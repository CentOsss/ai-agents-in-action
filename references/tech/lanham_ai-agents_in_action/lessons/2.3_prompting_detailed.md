# Раздел 2.3 — Prompting

**Prompting** — это процесс составления текстового запроса (prompt), который подается на вход языковой модели (LLM), чтобы получить желаемый результат. Качественный prompt позволяет управлять поведением модели, ограничивать или расширять область ответа, повышать точность и релевантность выдачи.

## Компоненты хорошего prompt
- **Роль (Persona):** Определяет, кем должна быть модель (учитель, эксперт, консультант и т.д.).
- **Профиль/Контекст:** Описывает ситуацию, уровень знаний пользователя, дополнительные детали.
- **Глобальные правила:** Устанавливают ограничения или требования к ответу.
- **Формат ответа:** Можно явно указать желаемый формат (список, таблица, код и т.д.).
- **Примеры (Few-shot prompting):** В prompt можно включать примеры вопросов и правильных ответов, чтобы модель лучше поняла задачу.

## Виды prompting
- **Zero-shot prompting:** Модель получает только инструкцию, без примеров.
- **One-shot prompting:** В prompt добавлен один пример.
- **Few-shot prompting:** В prompt несколько примеров, чтобы задать паттерн.

## Практические советы по созданию prompt
- Будьте максимально конкретны: чем точнее запрос, тем лучше результат.
- Указывайте роль и стиль, если это важно.
- Используйте ограничения (например, "ответь не более 100 слов").
- Проверяйте результат и корректируйте prompt при необходимости.
- Для сложных задач используйте few-shot prompting.

## Пример из практики (Python)
В курсе есть скрипт `development/projects/GPT-Agents/chapter_2/prompt_engineering.py`, который позволяет запускать различные тактики prompting и тестировать их на практике. В нем реализовано:
- Выбор файла с примерами prompt'ов.
- Загрузка и парсинг prompt'ов.
- Отправка prompt'а в LLM (OpenAI или локальная модель).
- Получение и вывод ответа.

## Вопросы для самопроверки
1. Что такое prompting и зачем он нужен при работе с LLM?
2. Какие компоненты может содержать хороший prompt?
3. В чем разница между zero-shot, one-shot и few-shot prompting?
4. Почему важно указывать роль и контекст в prompt?
5. Как можно улучшить результат, если модель отвечает не так, как ожидается? 